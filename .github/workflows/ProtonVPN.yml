name: Scrape Proton VPN Server Data

on:
  workflow_dispatch:
  schedule:
    # Run daily at 2 AM UTC
    - cron: "0 2 * * *"

jobs:
  scrape-protonvpn-servers:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Create directory if not exists
        run: mkdir -p ExternalData
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install Python dependencies
        run: |
          pip install requests beautifulsoup4 lxml html5lib
      
      - name: Scrape Proton VPN server data
        run: |
          python3 << 'EOF'
          import requests
          import json
          import re
          from datetime import datetime, timezone
          import time
          
          def fetch_proton_api():
              """Fetch Proton VPN server data from API"""
              print("=== Fetching Proton VPN API Data ===")
              
              # Try multiple API endpoints with different approaches
              api_endpoints = [
                  {
                      'url': 'https://api.protonvpn.ch/vpn/logicals',
                      'headers': {
                          'User-Agent': 'ProtonVPN/4.0.0 (Linux)',
                          'Accept': 'application/json',
                          'x-pm-appversion': '4.0.0'
                      }
                  },
                  {
                      'url': 'https://api.protonmail.ch/vpn/logicals',
                      'headers': {
                          'User-Agent': 'ProtonVPN/4.0.0 (Linux)',
                          'Accept': 'application/json',
                          'x-pm-appversion': '4.0.0'
                      }
                  },
                  {
                      'url': 'https://api.protonvpn.ch/vpn/config',
                      'headers': {
                          'User-Agent': 'ProtonVPN/4.0.0 (Linux)',
                          'Accept': 'application/json'
                      }
                  },
                  # Try without authentication - public endpoints
                  {
                      'url': 'https://api.protonvpn.ch/vpn/logicals',
                      'headers': {
                          'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                          'Accept': 'application/json'
                      }
                  },
                  # Alternative ProtonVPN API
                  {
                      'url': 'https://api.protonvpn.ch/api/vpn/logicals',
                      'headers': {
                          'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                          'Accept': 'application/json'
                      }
                  }
              ]
              
              for i, endpoint in enumerate(api_endpoints):
                  try:
                      print(f"Trying endpoint {i+1}: {endpoint['url']}")
                      response = requests.get(
                          endpoint['url'], 
                          headers=endpoint['headers'], 
                          timeout=30
                      )
                      
                      print(f"  Status: {response.status_code}")
                      print(f"  Content-Type: {response.headers.get('Content-Type', 'Unknown')}")
                      print(f"  Response size: {len(response.content)} bytes")
                      
                      if response.status_code == 200:
                          try:
                              data = response.json()
                              print(f"  ✅ Valid JSON response")
                              
                              # Check if response contains server data
                              servers = None
                              if isinstance(data, dict):
                                  servers = data.get('LogicalServers', data.get('Servers', data.get('servers')))
                                  if not servers and 'Code' in data:
                                      print(f"  API Response Code: {data.get('Code')}")
                                      continue
                              elif isinstance(data, list):
                                  servers = data
                              
                              if servers and len(servers) > 0:
                                  print(f"  🎯 Found {len(servers)} servers!")
                                  print(f"  Sample server keys: {list(servers[0].keys()) if isinstance(servers[0], dict) else 'Not a dict'}")
                                  return data, servers
                              else:
                                  print(f"  ❌ No server data found in response")
                                  
                          except json.JSONDecodeError as e:
                              print(f"  ❌ Invalid JSON: {e}")
                              # Show first 200 chars of response for debugging
                              preview = response.text[:200].replace('\n', '\\n')
                              print(f"  Response preview: {preview}")
                      else:
                          print(f"  ❌ HTTP Error: {response.status_code} - {response.reason}")
                          if response.status_code == 401:
                              print(f"  Authentication required")
                          elif response.status_code == 403:
                              print(f"  Access forbidden")
                          
                  except requests.RequestException as e:
                      print(f"  ❌ Request failed: {e}")
                  except Exception as e:
                      print(f"  ❌ Unexpected error: {e}")
              
              print("No working API endpoints found")
              return None, None
          
          def process_api_servers(raw_data, servers):
              """Process server data from API response"""
              print(f"=== Processing {len(servers)} API Servers ===")
              
              processed_servers = []
              country_counts = {}
              
              for i, server in enumerate(servers):
                  if not isinstance(server, dict):
                      continue
                  
                  # Extract server information with multiple possible field names
                  server_name = server.get('Name', server.get('name', server.get('ServerName', '')))
                  domain = server.get('Domain', server.get('domain', server.get('EntryDomain', '')))
                  entry_ip = server.get('EntryIP', server.get('entry_ip', server.get('EntryIp', '')))
                  exit_ip = server.get('ExitIP', server.get('exit_ip', server.get('ExitIp', '')))
                  
                  # Extract location information
                  country = server.get('ExitCountry', server.get('Country', server.get('country', '')))
                  city = server.get('City', server.get('city', ''))
                  
                  # Extract features and tier
                  features = []
                  tier = server.get('Tier', server.get('tier', 0))
                  feature_flags = server.get('Features', server.get('features', 0))
                  
                  # Decode feature flags (if numeric)
                  if isinstance(feature_flags, int):
                      if feature_flags & 1:  # Secure Core
                          features.append('Secure Core')
                      if feature_flags & 2:  # Tor
                          features.append('TOR')
                      if feature_flags & 4:  # P2P
                          features.append('P2P')
                      if feature_flags & 8:  # Streaming
                          features.append('Streaming')
                  elif isinstance(feature_flags, list):
                      features.extend(feature_flags)
                  
                  # Determine server type
                  if 'Secure Core' in features or tier >= 2:
                      server_type = 'Secure Core'
                  elif tier == 0:
                      server_type = 'Free'
                  else:
                      server_type = 'Plus'
                  
                  # Count servers per country
                  if country:
                      country_counts[country] = country_counts.get(country, 0) + 1
                  
                  processed_server = {
                      'server_name': server_name,
                      'domain': domain,
                      'entry_ip': entry_ip,
                      'exit_ip': exit_ip,
                      'country': country,
                      'city': city,
                      'features': features,
                      'server_type': server_type,
                      'tier': tier,
                      'load': server.get('Load', server.get('load', 0)),
                      'score': server.get('Score', server.get('score', 0))
                  }
                  
                  processed_servers.append(processed_server)
                  
                  # Show progress for large datasets
                  if i % 100 == 0 and i > 0:
                      print(f"  Processed {i}/{len(servers)} servers...")
              
              print(f"✅ Processed {len(processed_servers)} servers")
              print(f"Countries found: {len(country_counts)}")
              print("Top 10 countries by server count:")
              for country, count in sorted(country_counts.items(), key=lambda x: x[1], reverse=True)[:10]:
                  print(f"  {country}: {count} servers")
              
              return processed_servers
          
          def aggregate_by_country(servers):
              """Aggregate individual servers by country for summary stats"""
              country_data = {}
              
              for server in servers:
                  country = server['country']
                  if not country:
                      continue
                  
                  if country not in country_data:
                      country_data[country] = {
                          'country': country,
                          'server_count': 0,
                          'plus_count': 0,
                          'secure_core_count': 0,
                          'free_count': 0,
                          'cities': set(),
                          'features': set(),
                          'servers': []
                      }
                  
                  data = country_data[country]
                  data['server_count'] += 1
                  data['servers'].append(server)
                  
                  if server['server_type'] == 'Plus':
                      data['plus_count'] += 1
                  elif server['server_type'] == 'Secure Core':
                      data['secure_core_count'] += 1
                  elif server['server_type'] == 'Free':
                      data['free_count'] += 1
                  
                  if server['city']:
                      data['cities'].add(server['city'])
                  
                  data['features'].update(server['features'])
              
              # Convert to final format
              aggregated = []
              for country, data in country_data.items():
                  aggregated.append({
                      'country': country,
                      'server_count': data['server_count'],
                      'city_count': len(data['cities']),
                      'plus_servers': data['plus_count'],
                      'secure_core_servers': data['secure_core_count'],
                      'free_servers': data['free_count'],
                      'features': list(data['features']),
                      'cities': list(data['cities'])
                  })
              
              return sorted(aggregated, key=lambda x: x['server_count'], reverse=True)
          
          def main():
              print("Starting Proton VPN server data collection...")
              
              # Try to fetch from API
              raw_data, api_servers = fetch_proton_api()
              
              if api_servers:
                  # Process the API data
                  processed_servers = process_api_servers(raw_data, api_servers)
                  country_summary = aggregate_by_country(processed_servers)
                  
                  # Calculate totals
                  total_servers = len(processed_servers)
                  total_countries = len(country_summary)
                  total_plus = sum(s['plus_servers'] for s in country_summary)
                  total_secure_core = sum(s['secure_core_servers'] for s in country_summary)
                  total_free = sum(s['free_servers'] for s in country_summary)
                  
                  print(f"\n=== Final Statistics ===")
                  print(f"Total servers: {total_servers}")
                  print(f"Total countries: {total_countries}")
                  print(f"Plus servers: {total_plus}")
                  print(f"Secure Core servers: {total_secure_core}")
                  print(f"Free servers: {total_free}")
                  
                  # Create output data structure
                  data = {
                      'metadata': {
                          'source': 'Proton VPN API',
                          'scraped_at': datetime.now(timezone.utc).isoformat(),
                          'total_servers': total_servers,
                          'total_countries': total_countries,
                          'total_plus_servers': total_plus,
                          'total_secure_core_servers': total_secure_core,
                          'total_free_servers': total_free,
                          'data_quality': 'api_direct'
                      },
                      'country_summary': country_summary,
                      'individual_servers': processed_servers[:1000],  # Limit to first 1000 for file size
                      'sample_raw_data': raw_data if isinstance(raw_data, dict) else {}
                  }
                  
              else:
                  print("API failed, using manual fallback data...")
                  # Fallback data
                  country_summary = [
                      {'country': 'United States', 'server_count': 3188, 'city_count': 17, 'plus_servers': 3184, 'secure_core_servers': 4, 'free_servers': 0, 'features': ['Streaming', 'P2P', 'TOR'], 'cities': ['New York', 'Los Angeles', 'Chicago']},
                      {'country': 'Canada', 'server_count': 849, 'city_count': 3, 'plus_servers': 846, 'secure_core_servers': 3, 'free_servers': 0, 'features': ['Streaming', 'P2P'], 'cities': ['Toronto', 'Vancouver', 'Montreal']},
                      {'country': 'Switzerland', 'server_count': 790, 'city_count': 1, 'plus_servers': 790, 'secure_core_servers': 0, 'free_servers': 0, 'features': ['Streaming', 'P2P', 'TOR'], 'cities': ['Zurich']},
                      {'country': 'United Kingdom', 'server_count': 553, 'city_count': 5, 'plus_servers': 550, 'secure_core_servers': 3, 'free_servers': 0, 'features': ['Streaming', 'P2P'], 'cities': ['London', 'Manchester']},
                      {'country': 'Germany', 'server_count': 483, 'city_count': 2, 'plus_servers': 480, 'secure_core_servers': 3, 'free_servers': 0, 'features': ['Streaming', 'P2P', 'TOR'], 'cities': ['Frankfurt', 'Berlin']},
                  ]
                  
                  data = {
                      'metadata': {
                          'source': 'Manual Fallback Data',
                          'scraped_at': datetime.now(timezone.utc).isoformat(),
                          'total_servers': sum(s['server_count'] for s in country_summary),
                          'total_countries': len(country_summary),
                          'data_quality': 'manual_fallback'
                      },
                      'country_summary': country_summary,
                      'individual_servers': [],
                      'sample_raw_data': {}
                  }
              
              # Save JSON
              with open('ExternalData/ProtonVPNServers.json', 'w') as f:
                  json.dump(data, f, indent=2)
              
              # Save CSV - Country Summary
              import csv
              with open('ExternalData/ProtonVPNServers.csv', 'w', newline='', encoding='utf-8') as f:
                  writer = csv.writer(f)
                  writer.writerow(['Country', 'TotalServers', 'CityCount', 'PlusServers', 'SecureCoreServers', 'FreeServers', 'Features', 'Cities'])
                  
                  for country in data['country_summary']:
                      writer.writerow([
                          country['country'],
                          country['server_count'],
                          country['city_count'],
                          country['plus_servers'],
                          country['secure_core_servers'],
                          country['free_servers'],
                          '; '.join(country['features']),
                          '; '.join(country['cities'])
                      ])
              
              # Save detailed server list if we have it
              if data['individual_servers']:
                  with open('ExternalData/ProtonVPN_DetailedServers.csv', 'w', newline='', encoding='utf-8') as f:
                      writer = csv.writer(f)
                      writer.writerow(['ServerName', 'Domain', 'EntryIP', 'ExitIP', 'Country', 'City', 'ServerType', 'Tier', 'Features'])
                      
                      for server in data['individual_servers']:
                          writer.writerow([
                              server['server_name'],
                              server['domain'],
                              server['entry_ip'],
                              server['exit_ip'],
                              server['country'],
                              server['city'],
                              server['server_type'],
                              server['tier'],
                              '; '.join(server['features'])
                          ])
                  print("Detailed server list saved to ProtonVPN_DetailedServers.csv")
              
              print(f"\n=== Export Complete ===")
              print(f"Country summary: ExternalData/ProtonVPNServers.csv")
              print(f"Full data: ExternalData/ProtonVPNServers.json")
              if data['individual_servers']:
                  print(f"Detailed servers: ExternalData/ProtonVPN_DetailedServers.csv")
          
          if __name__ == "__main__":
              main()
          EOF
      
      - name: Generate statistics
        run: |
          echo "=== Proton VPN Server Statistics ==="
          
          if [ -f "ExternalData/ProtonVPNServers.csv" ]; then
            echo "Total countries: $(tail -n +2 ExternalData/ProtonVPNServers.csv | wc -l)"
            
            echo ""
            echo "Top 10 countries by server count:"
            tail -n +2 ExternalData/ProtonVPNServers.csv | sort -t',' -k2 -nr | head -10 | awk -F',' '{print $1 ": " $2 " servers"}'
            
            echo ""
            echo "Total server counts:"
            tail -n +2 ExternalData/ProtonVPNServers.csv | awk -F',' '{
              total += $2;
              plus += $4;
              secure += $5;
              free += $6;
            } END {
              print "Total servers: " total;
              print "Plus servers: " plus;
              print "Secure Core servers: " secure;
              print "Free servers: " free;
            }'
            
            echo ""
            if [ -f "ExternalData/ProtonVPN_DetailedServers.csv" ]; then
              echo "Detailed server entries: $(tail -n +2 ExternalData/ProtonVPN_DetailedServers.csv | wc -l)"
              echo "Sample servers with IPs:"
              tail -n +2 ExternalData/ProtonVPN_DetailedServers.csv | head -5 | awk -F',' '{print "  " $1 " (" $5 "): " $3 " -> " $4}'
            fi
          else
            echo "No CSV file found - scraping may have failed"
          fi
      
      - name: Validate scraped data
        run: |
          python3 << 'EOF'
          import json
          import sys
          
          try:
              with open('ExternalData/ProtonVPNServers.json', 'r') as f:
                  data = json.load(f)
              
              countries = data.get('country_summary', [])
              servers = data.get('individual_servers', [])
              metadata = data.get('metadata', {})
              
              print(f"Validation Results:")
              print(f"- Valid JSON: ✓")
              print(f"- Countries found: {len(countries)}")
              print(f"- Individual servers: {len(servers)}")
              print(f"- Metadata present: {'✓' if metadata else '✗'}")
              print(f"- Data quality: {metadata.get('data_quality', 'unknown')}")
              
              if len(countries) == 0:
                  print("❌ No countries found - scraping failed")
                  sys.exit(1)
              
              total_servers = sum(c.get('server_count', 0) for c in countries)
              print(f"- Total servers: {total_servers}")
              
              if servers:
                  sample_server = servers[0]
                  has_ips = bool(sample_server.get('entry_ip') or sample_server.get('exit_ip'))
                  print(f"- IP addresses available: {'✓' if has_ips else '✗'}")
                  if has_ips:
                      print(f"- Sample server: {sample_server.get('server_name')} - {sample_server.get('entry_ip')} -> {sample_server.get('exit_ip')}")
              
              print(f"✓ Data validation passed")
              
          except Exception as e:
              print(f"❌ Validation failed: {e}")
              sys.exit(1)
          EOF
      
      - name: Commit and push changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "Update Proton VPN servers data with API - $(date -u '+%Y-%m-%d %H:%M UTC')"
          file_pattern: 'ExternalData/ProtonVPN*.*'
          commit_user_name: 'Proton VPN API Scraper'
          commit_user_email: 'actions@github.com'
          push_options: '--force-with-lease'
      
      - name: Create summary
        run: |
          echo "## Proton VPN Server Collection Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "ExternalData/ProtonVPNServers.json" ]; then
            echo "✅ **Collection Successful**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            python3 -c "
          import json
          with open('ExternalData/ProtonVPNServers.json', 'r') as f:
              data = json.load(f)
          
          metadata = data['metadata']
          countries = data['country_summary']
          servers = data['individual_servers']
          
          print(f'- **Data Source:** {metadata.get(\"source\", \"Unknown\")}')
          print(f'- **Total Countries:** {len(countries)}')
          print(f'- **Total Servers:** {metadata.get(\"total_servers\", \"N/A\")}')
          print(f'- **Plus Servers:** {metadata.get(\"total_plus_servers\", \"N/A\")}')
          print(f'- **Secure Core Servers:** {metadata.get(\"total_secure_core_servers\", \"N/A\")}')
          print(f'- **Individual Server Records:** {len(servers)}')
          print(f'- **Data Quality:** {metadata.get(\"data_quality\", \"Unknown\")}')
          " >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Collection Failed**" >> $GITHUB_STEP_SUMMARY
            echo "No data files were created." >> $GITHUB_STEP_SUMMARY
          fi
