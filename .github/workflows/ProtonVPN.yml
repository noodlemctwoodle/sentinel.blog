name: Pull Proton VPN Server Data
on:
  workflow_dispatch:
  schedule:
    # Run daily at midnight UTC
    - cron: "0 0 * * *"

jobs:
  pull-protonvpn-data:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Create directory if not exists
        run: mkdir -p ExternalData
      
      - name: Attempt to fetch detailed server data from API
        run: |
          echo "Attempting to fetch detailed Proton VPN server data from API..."
          
          # Try the old API endpoints (these may not work anymore)
          API_ENDPOINTS=(
            "https://api.protonvpn.ch/vpn/logicals"
            "https://api.protonmail.ch/vpn/logicals"
            "https://api.protonvpn.com/vpn/logicals"
          )
          
          API_SUCCESS=0
          for endpoint in "${API_ENDPOINTS[@]}"; do
            echo "Trying endpoint: $endpoint"
            if curl -s -f -H "Accept: application/json" "$endpoint" > /tmp/api_response.json 2>/dev/null; then
              if [ -s /tmp/api_response.json ] && jq empty /tmp/api_response.json 2>/dev/null; then
                echo "✓ Successfully fetched data from: $endpoint"
                
                # Process the detailed API data
                python3 -c "
                import json, sys
                
                with open('/tmp/api_response.json', 'r') as f:
                    data = json.load(f)
                
                print('ExitIP,ServicesDown,City,ExitCountry,EntryCountry,Status,ServerID,Name,Features')
                
                if 'LogicalServers' in data:
                    for server in data['LogicalServers']:
                        name = server.get('Name', '')
                        features = server.get('Features', 0)
                        tier = server.get('Tier', 0)
                        status = 'Active' if server.get('Status', 0) == 1 else 'Inactive'
                        city = server.get('City', '')
                        country = server.get('ExitCountry', '')
                        entry_country = server.get('EntryCountry', '')
                        server_id = server.get('ID', '')
                        
                        # Process individual physical servers
                        if 'Servers' in server:
                            for physical_server in server['Servers']:
                                exit_ip = physical_server.get('EntryIP', '')
                                services_down = 'False'  # Assume services are up
                                
                                print(f'\"{exit_ip}\",\"{services_down}\",\"{city}\",\"{country}\",\"{entry_country}\",\"{status}\",\"{server_id}\",\"{name}\",\"{features}\"')
                        else:
                            # Fallback for servers without detailed IP info
                            print(f'\"\",\"False\",\"{city}\",\"{country}\",\"{entry_country}\",\"{status}\",\"{server_id}\",\"{name}\",\"{features}\"')
                " > ExternalData/ProtonVPNServers.csv
                
                API_SUCCESS=1
                break
              fi
            fi
          done
          
          if [ $API_SUCCESS -eq 0 ]; then
            echo "⚠️ API endpoints are not accessible. Falling back to web scraping..."
            
            # Fallback: scrape the public website for basic server information
            curl -s "https://protonvpn.com/vpn-servers" | \
            python3 -c "
            import sys, re
            html = sys.stdin.read()
            
            print('ExitIP,ServicesDown,City,ExitCountry,EntryCountry,Status,ServerID,Name,Features')
            
            # Find all country sections with server counts
            pattern = r'([A-Za-z\s&\(\)\']+?)\n- Adblocker \(NetShield\)\n.*?(\d+) servers? \| (\d+) cit'
            countries = re.findall(pattern, html, re.MULTILINE | re.DOTALL)
            
            for match in countries:
                country = match[0].strip()
                server_count = int(match[1])
                cities = int(match[2])
                
                # Extract features for this country
                country_pattern = re.escape(country) + r'\n- Adblocker.*?(?=\n[A-Za-z\s&\(\)\']+\n-|\nSecure Core|\nLearn more|\Z)'
                country_section = re.search(country_pattern, html, re.DOTALL)
                
                features = []
                feature_codes = []
                if country_section:
                    section_text = country_section.group(0)
                    if '- P2P' in section_text: 
                        features.append('P2P')
                        feature_codes.append('4')
                    if '- Streaming support' in section_text: 
                        features.append('Streaming')
                        feature_codes.append('16')
                    if '- TOR' in section_text: 
                        features.append('TOR')
                        feature_codes.append('8')
                
                # Generate a feature code (sum of individual features)
                feature_code = str(sum(int(x) for x in feature_codes)) if feature_codes else '0'
                
                # Since we don't have individual server IPs, create placeholder entries
                for i in range(min(server_count, 10)):  # Limit to first 10 servers per country
                    server_name = f'{country[:2].upper()}#{i+1}'
                    print(f'\"N/A\",\"False\",\"{country}\",\"{country[:2].upper()}\",\"\",\"Active\",\"N/A\",\"{server_name}\",\"{feature_code}\"')
            " > ExternalData/ProtonVPNServers.csv
          fi
          
          # Verify file was created and has content
          if [ ! -s ExternalData/ProtonVPNServers.csv ]; then
            echo "Error: Output file is empty or doesn't exist"
            exit 1
          fi
          
          # Display first few lines for verification
          echo "Generated CSV content (first 10 lines):"
          head -10 ExternalData/ProtonVPNServers.csv
          
          # Count entries for logging (subtract 1 for header)
          entries=$(($(wc -l < ExternalData/ProtonVPNServers.csv) - 1))
          echo "Processed $entries ProtonVPN server entries"
          
          # Add a note about data limitations
          if [ $API_SUCCESS -eq 0 ]; then
            echo "Note: Detailed server data (IP addresses, server IDs) not available due to API restrictions."
            echo "Only basic country/server information extracted from public website."
          fi
      
      - name: Commit and push changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "Update Proton VPN servers - $(date -u +%Y-%m-%d)"
          file_pattern: 'ExternalData/ProtonVPNServers.csv'
          commit_user_name: 'Proton VPN Data Updater'
          commit_user_email: 'actions@github.com'
          push_options: '--force-with-lease'
