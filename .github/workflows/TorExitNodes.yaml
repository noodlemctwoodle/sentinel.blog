name: Pull TOR Exit Nodes Data

on:
  workflow_dispatch:
  schedule:
    - cron: "0 0 * * *"

jobs:
  pull-external-data:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Create directory
        run: mkdir -p ExternalData
      
      - name: Fetch all TOR sources
        run: |
          echo "Fetching TOR exit nodes from multiple sources..."
          
          curl -s "https://check.torproject.org/torbulkexitlist" > tor_bulk.txt
          echo "Bulk list: $(wc -l < tor_bulk.txt) lines"
          
          curl -s "https://onionoo.torproject.org/details?flag=Exit" > tor_onionoo.json
          echo "Onionoo API: $(wc -c < tor_onionoo.json) bytes"
          
          curl -s "https://torstatus.rueckgr.at/query_export.php/Tor_ip_list_EXIT.csv" > tor_rueckgr.csv
          echo "Rueckgr CSV: $(wc -l < tor_rueckgr.csv) lines"
          
          curl -s "https://www.dan.me.uk/torlist/" > tor_dan.txt
          echo "Dan.me.uk: $(wc -l < tor_dan.txt) lines"
          
          curl -s "https://api.hackertarget.com/torexit/?q=list" > tor_hackertarget.txt
          echo "HackerTarget: $(wc -l < tor_hackertarget.txt) lines"
      
      - name: Process data
        run: |
          echo "Processing and combining data..."
          
          # Initialize
          touch all_ips.txt
          
          # Process each source
          grep -E '^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$' tor_bulk.txt >> all_ips.txt || true
          
          if command -v jq >/dev/null; then
            jq -r '.relays[]?.exit_addresses[]? // .relays[]?.or_addresses[]?' tor_onionoo.json 2>/dev/null | grep -E '^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+' | sed 's/:[0-9]*$//' >> all_ips.txt || true
          fi
          
          tail -n +2 tor_rueckgr.csv | cut -d',' -f1 | grep -E '^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+' >> all_ips.txt || true
          
          grep -E '^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$' tor_dan.txt >> all_ips.txt || true
          
          grep -E '^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$' tor_hackertarget.txt >> all_ips.txt || true
          
          # Clean up
          sort all_ips.txt | uniq > validated_ips.txt
          
          total_ips=$(wc -l < validated_ips.txt)
          echo "Total unique IPs: $total_ips"
          
          # Create CSV
          echo "ExitIP,Country,City,Source" > ExternalData/TorExitNodes.csv
          while read ip; do
            echo "$ip,,,Multiple Sources" >> ExternalData/TorExitNodes.csv
          done < validated_ips.txt
      
      - name: Create JSON
        run: |
          python3 -c "
          import json
          from datetime import datetime
          
          with open('validated_ips.txt', 'r') as f:
              ips = [line.strip() for line in f if line.strip()]
          
          data = {
              'metadata': {
                  'source': 'Multiple TOR sources',
                  'updated': datetime.utcnow().isoformat() + 'Z',
                  'count': len(ips)
              },
              'TorExitNodes': ips
          }
          
          with open('ExternalData/TorExitNodes.json', 'w') as f:
              json.dump(data, f, indent=2)
          
          print(f'Created JSON with {len(ips)} IPs')
          "
      
      - name: Cleanup
        run: rm -f tor_*.txt tor_*.json tor_*.csv all_ips.txt validated_ips.txt
      
      - name: Commit changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "Update TOR exit nodes"
          file_pattern: 'ExternalData/TorExitNodes.*'
          push_options: '--force-with-lease'
