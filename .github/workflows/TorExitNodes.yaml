name: Pull TOR Exit Nodes Data

on:
  workflow_dispatch:
  schedule:
    - cron: "0 0 * * *"

env:
  # Add your API keys as GitHub secrets if using paid services
  IPAPI_KEY: ${{ secrets.IPAPI_KEY }}
  IPGEOLOCATION_KEY: ${{ secrets.IPGEOLOCATION_KEY }}

jobs:
  pull-external-data:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Create directory
        run: mkdir -p ExternalData
      
      - name: Setup Geolocation Databases
        run: |
          echo "Setting up geolocation databases..."
          
          # Try to download IP2Location alternative source
          echo "Attempting to download IP2Location LITE database..."
          if curl -s -o ip2location.csv "https://download.ip2location.com/lite/IP2LOCATION-LITE-DB11.CSV"; then
            if [ -s ip2location.csv ] && file ip2location.csv | grep -q "ASCII\|UTF"; then
              echo "Successfully downloaded IP2Location database: $(wc -l < ip2location.csv) records"
              mv ip2location.csv IP2LOCATION-LITE-DB11.CSV
            else
              echo "IP2Location download failed or returned invalid data"
              rm -f ip2location.csv
            fi
          else
            echo "Failed to download IP2Location database"
          fi
          
          # Create a simple country code database as fallback
          echo "Creating fallback country database..."
          cat > country_fallback.csv << 'EOF'
          # Simple country code mappings for common IP ranges
          # Format: start_ip,end_ip,country_code,country_name
          1.0.0.0,1.255.255.255,AU,Australia
          2.0.0.0,2.255.255.255,FR,France
          3.0.0.0,3.255.255.255,US,United States
          4.0.0.0,4.255.255.255,US,United States
          5.0.0.0,5.255.255.255,US,United States
          8.8.8.8,8.8.8.8,US,United States
          EOF
          
          # Verify what we have
          if [ -f "IP2LOCATION-LITE-DB11.CSV" ]; then
            echo "✓ IP2Location database available"
          else
            echo "⚠ Will use API-only geolocation"
          fi
      
      - name: Install Python dependencies
        run: |
          pip install requests maxminddb geoip2 ipaddress
      
      - name: Fetch all TOR sources
        run: |
          echo "Fetching TOR exit nodes from multiple sources..."
          curl -s "https://check.torproject.org/torbulkexitlist" > tor_bulk.txt
          echo "Bulk list: $(wc -l < tor_bulk.txt) lines"
          curl -s "https://onionoo.torproject.org/details?flag=Exit" > tor_onionoo.json
          echo "Onionoo API: $(wc -c < tor_onionoo.json) bytes"
          curl -s "https://torstatus.rueckgr.at/query_export.php/Tor_ip_list_EXIT.csv" > tor_rueckgr.csv
          echo "Rueckgr CSV: $(wc -l < tor_rueckgr.csv) lines"
          curl -s "https://www.dan.me.uk/torlist/" > tor_dan.txt
          echo "Dan.me.uk: $(wc -l < tor_dan.txt) lines"
          curl -s "https://api.hackertarget.com/torexit/?q=list" > tor_hackertarget.txt
          echo "HackerTarget: $(wc -l < tor_hackertarget.txt) lines"
      
      - name: Process data
        run: |
          echo "Processing and combining data..."
          touch all_ips.txt
          grep -E '^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$' tor_bulk.txt >> all_ips.txt || true
          if command -v jq >/dev/null; then
            jq -r '.relays[]?.exit_addresses[]? // .relays[]?.or_addresses[]?' tor_onionoo.json 2>/dev/null | grep -E '^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+' | sed 's/:[0-9]*$//' >> all_ips.txt || true
          fi
          tail -n +2 tor_rueckgr.csv | cut -d',' -f1 | grep -E '^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+' >> all_ips.txt || true
          grep -E '^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$' tor_dan.txt >> all_ips.txt || true
          grep -E '^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$' tor_hackertarget.txt >> all_ips.txt || true
          sort all_ips.txt | uniq > unique_ips.txt
          total_ips=$(wc -l < unique_ips.txt)
          echo "Total unique IPs: $total_ips"
      
      - name: Enhanced geolocation enrichment
        run: |
          python3 -c "
          import json
          import csv
          import requests
          import time
          import ipaddress
          from datetime import datetime
          
          # Helper function to validate IP
          def is_valid_ip(ip):
              try:
                  ipaddress.ip_address(ip)
                  return True
              except ValueError:
                  return False
          
          # Load IP2Location database
          def load_ip2location_db():
              ip_ranges = []
              try:
                  with open('IP2LOCATION-LITE-DB11.CSV', 'r') as f:
                      reader = csv.reader(f)
                      for row in reader:
                          # Skip header or invalid rows
                          if len(row) >= 6 and row[0].isdigit():
                              try:
                                  ip_from = int(row[0])
                                  ip_to = int(row[1])
                                  country_code = row[2].strip('\"')
                                  country_name = row[3].strip('\"')
                                  region = row[4].strip('\"') if len(row) > 4 else ''
                                  city = row[5].strip('\"') if len(row) > 5 else ''
                                  if country_code and country_code != '-':
                                      ip_ranges.append({
                                          'from': ip_from,
                                          'to': ip_to,
                                          'cc': country_code,
                                          'cn': country_name,
                                          'region': region,
                                          'city': city
                                      })
                              except (ValueError, IndexError):
                                  continue
                  print(f'Loaded {len(ip_ranges)} IP ranges from IP2Location')
                  return ip_ranges
              except FileNotFoundError:
                  print('IP2Location database not found, using API-only mode')
                  return []
              except Exception as e:
                  print(f'Error loading IP2Location database: {e}')
                  return []
          
          # Convert IP to integer for range lookup
          def ip_to_int(ip):
              parts = ip.split('.')
              return (int(parts[0]) << 24) + (int(parts[1]) << 16) + (int(parts[2]) << 8) + int(parts[3])
          
          # Lookup IP in database
          def lookup_ip_in_db(ip, ip_ranges):
              ip_int = ip_to_int(ip)
              for range_data in ip_ranges:
                  if range_data['from'] <= ip_int <= range_data['to']:
                      return {
                          'cc': range_data['cc'],
                          'cn': range_data['cn'],
                          'city': range_data['city'],
                          'region': range_data['region']
                      }
              return None
          
          # Free API lookup functions with better error handling
          def lookup_ip_api(ip):
              try:
                  response = requests.get(f'http://ip-api.com/json/{ip}?fields=status,message,country,countryCode,region,regionName,city', timeout=10)
                  if response.status_code == 200:
                      data = response.json()
                      if data.get('status') == 'success':
                          return {
                              'cc': data.get('countryCode', ''),
                              'cn': data.get('country', ''),
                              'city': data.get('city', ''),
                              'region': data.get('regionName', ''),
                              'source': 'ip-api.com'
                          }
                      else:
                          print(f'IP-API failed for {ip}: {data.get(\"message\", \"Unknown error\")}')
              except Exception as e:
                  print(f'IP-API error for {ip}: {e}')
              return None
          
          def lookup_ipapi_co(ip):
              try:
                  response = requests.get(f'https://ipapi.co/{ip}/json/', timeout=10)
                  if response.status_code == 200:
                      data = response.json()
                      if 'error' not in data and data.get('country_code'):
                          return {
                              'cc': data.get('country_code', ''),
                              'cn': data.get('country_name', ''),
                              'city': data.get('city', ''),
                              'region': data.get('region', ''),
                              'source': 'ipapi.co'
                          }
                      else:
                          print(f'IPAPI.co failed for {ip}: {data.get(\"error\", \"No data\")}')
              except Exception as e:
                  print(f'IPAPI.co error for {ip}: {e}')
              return None
          
          def lookup_geojs(ip):
              try:
                  response = requests.get(f'https://get.geojs.io/v1/ip/geo/{ip}.json', timeout=10)
                  if response.status_code == 200:
                      data = response.json()
                      if data.get('country_code'):
                          return {
                              'cc': data.get('country_code', ''),
                              'cn': data.get('country', ''),
                              'city': data.get('city', ''),
                              'region': data.get('region', ''),
                              'source': 'geojs.io'
                          }
              except Exception as e:
                  print(f'GeoJS error for {ip}: {e}')
              return None
          
          def lookup_ipinfo_io(ip):
              try:
                  response = requests.get(f'https://ipinfo.io/{ip}/json', timeout=10)
                  if response.status_code == 200:
                      data = response.json()
                      if data.get('country'):
                          return {
                              'cc': data.get('country', ''),
                              'cn': data.get('country', ''),  # ipinfo doesn't provide full country name in free tier
                              'city': data.get('city', ''),
                              'region': data.get('region', ''),
                              'source': 'ipinfo.io'
                          }
              except Exception as e:
                  print(f'IPInfo.io error for {ip}: {e}')
              return None
          
          # Load Onionoo data for initial enrichment
          ip_to_geo = {}
          onionoo_count = 0
          try:
              with open('tor_onionoo.json', 'r') as f:
                  onionoo = json.load(f)
              for relay in onionoo.get('relays', []):
                  country = relay.get('country', '')
                  country_name = relay.get('country_name', '')
                  city = relay.get('city_name', '')
                  addresses = relay.get('exit_addresses', []) + relay.get('or_addresses', [])
                  for addr in addresses:
                      ip = addr.split(':')[0]
                      if is_valid_ip(ip):
                          ip_to_geo[ip] = {
                              'cc': country,
                              'cn': country_name,
                              'city': city,
                              'source': 'Onionoo API'
                          }
                          onionoo_count += 1
              print(f'Loaded geo data from Onionoo for {onionoo_count} IPs')
          except Exception as e:
              print(f'Error loading Onionoo data: {e}')
          
          # Load IP2Location database
          ip_ranges = load_ip2location_db()
          
          # Process unique IPs and enrich with multiple sources
          enriched_nodes = []
          api_calls = 0
          max_api_calls = 900  # Leave some buffer for rate limits
          
          with open('unique_ips.txt', 'r') as f:
              ips = [line.strip() for line in f if line.strip() and is_valid_ip(line.strip())]
          
          print(f'Processing {len(ips)} unique IPs...')
          
          for i, ip in enumerate(ips):
              if i % 100 == 0:
                  print(f'Processed {i}/{len(ips)} IPs')
              
              geo_data = None
              source = 'Unknown'
              
              # Try Onionoo first (already loaded)
              if ip in ip_to_geo:
                  geo_data = ip_to_geo[ip]
              
              # Try IP2Location database (offline lookup)
              elif ip_ranges:
                  db_result = lookup_ip_in_db(ip, ip_ranges)
                  if db_result:
                      geo_data = {
                          'cc': db_result['cc'],
                          'cn': db_result['cn'],
                          'city': db_result['city'],
                          'source': 'IP2Location DB'
                      }
              
              # Try free APIs if still no data and under rate limit
              elif api_calls < max_api_calls:
                  # Distribute calls across different APIs to maximize coverage
                  api_choice = api_calls % 4
                  
                  if api_choice == 0:
                      # Try ip-api.com (most generous rate limit: 45 requests/minute)
                      geo_data = lookup_ip_api(ip)
                      if geo_data:
                          api_calls += 1
                          time.sleep(1.5)  # Stay under rate limit
                  
                  elif api_choice == 1 and api_calls < max_api_calls - 50:
                      # Try ipapi.co (1000/day, more conservative)
                      geo_data = lookup_ipapi_co(ip)
                      if geo_data:
                          api_calls += 1
                          time.sleep(1)
                  
                  elif api_choice == 2:
                      # Try geojs.io 
                      geo_data = lookup_geojs(ip)
                      if geo_data:
                          api_calls += 1
                          time.sleep(0.5)
                  
                  elif api_choice == 3:
                      # Try ipinfo.io
                      geo_data = lookup_ipinfo_io(ip)
                      if geo_data:
                          api_calls += 1
                          time.sleep(1)
              
              # Create node entry
              if geo_data:
                  node = {
                      'ip': ip,
                      'country_code': geo_data.get('cc', ''),
                      'country_name': geo_data.get('cn', ''),
                      'city': geo_data.get('city', ''),
                      'source': geo_data.get('source', 'Multiple Sources')
                  }
              else:
                  node = {
                      'ip': ip,
                      'country_code': '',
                      'country_name': '',
                      'city': '',
                      'source': 'No geo data'
                  }
              
              enriched_nodes.append(node)
          
          # Calculate enrichment statistics
          enriched_count = sum(1 for node in enriched_nodes if node['country_code'])
          enrichment_percentage = round(enriched_count / len(enriched_nodes) * 100, 1) if enriched_nodes else 0
          
          # Count by source
          source_counts = {}
          for node in enriched_nodes:
              source = node['source']
              source_counts[source] = source_counts.get(source, 0) + 1
          
          print(f'Enrichment summary:')
          for source, count in source_counts.items():
              print(f'  {source}: {count} IPs')
          print(f'Total API calls made: {api_calls}')
          
          # Create enriched CSV
          with open('ExternalData/TorExitNodes.csv', 'w', newline='') as f:
              writer = csv.writer(f)
              writer.writerow(['ExitIP', 'CountryCode', 'CountryName', 'City', 'Source'])
              for node in enriched_nodes:
                  writer.writerow([
                      node['ip'],
                      node['country_code'],
                      node['country_name'],
                      node['city'],
                      node['source']
                  ])
          
          # Create enriched JSON
          data = {
              'metadata': {
                  'source': 'Multiple TOR sources with enhanced geolocation',
                  'updated': datetime.utcnow().isoformat() + 'Z',
                  'count': len(enriched_nodes),
                  'enriched_count': enriched_count,
                  'enrichment_percentage': enrichment_percentage,
                  'api_calls_used': api_calls,
                  'source_breakdown': source_counts
              },
              'TorExitNodes': enriched_nodes
          }
          
          with open('ExternalData/TorExitNodes.json', 'w') as f:
              json.dump(data, f, indent=2)
          
          print(f'Created enriched data: {len(enriched_nodes)} IPs ({enriched_count} with geo data, {enrichment_percentage}% enriched)')
          "
      
      - name: Generate statistics
        run: |
          echo "=== TOR Exit Node Statistics ==="
          echo "Top 15 countries by exit node count:"
          tail -n +2 ExternalData/TorExitNodes.csv | cut -d',' -f3 | grep -v '^$' | sort | uniq -c | sort -nr | head -15
          
          echo ""
          echo "Data sources breakdown:"
          tail -n +2 ExternalData/TorExitNodes.csv | cut -d',' -f5 | sort | uniq -c | sort -nr
          
          echo ""
          echo "Total unique exit nodes: $(tail -n +2 ExternalData/TorExitNodes.csv | wc -l)"
          echo "Nodes with geo data: $(tail -n +2 ExternalData/TorExitNodes.csv | awk -F',' '$2 != \"\"' | wc -l)"
      
      - name: Cleanup
        run: |
          rm -f tor_*.txt tor_*.json tor_*.csv all_ips.txt unique_ips.txt
          rm -f IP2LOCATION-LITE-DB11.CSV* *.zip *.csv country_fallback.csv ip2location.csv
      
      - name: Commit changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "Update TOR exit nodes with enhanced geolocation"
          file_pattern: 'ExternalData/TorExitNodes.*'
          push_options: '--force-with-lease'
