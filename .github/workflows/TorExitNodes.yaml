- name: Enrich with country data
        run: |
          echo "Adding country enrichment from Onionoo API..."
          
          python3 -c "
          import json
          import csv
          
          # Load Onionoo data
          try:
              with open('tor_onionoo.json', 'r') as f:
                  onionoo_data = json.load(f)
          except:
              print('No Onionoo data available')
              exit()
          
          # Create IP to country mapping
          ip_to_country = {}
          for relay in onionoo_data.get('relays', []):
              country = relay.get('country', '')
              country_name = relay.get('country_name', '')
              city = relay.get('city_name', '')
              
              # Get exit addresses
              exit_addresses = relay.get('exit_addresses', [])
              or_addresses = relay.get('or_addresses', [])
              
              all_addresses = exit_addresses + or_addresses
              
              for addr in all_addresses:
                  ip = addr.split(':')[0]  # Remove port if present
                  if '.' in ip and len(ip.split('.')) == 4:  # Basic IP validation
                      ip_to_country[ip] = {
                          'country_code': country,
                          'country_name': country_name,
                          'city': city
                      }
          
          print(f'Created mapping for {len(ip_to_country)} IPs')
          
          # Read existing CSV and enrich
          enriched_rows = []
          with open('ExternalData/TorExitNodes.csv', 'r') as f:
              reader = csv.DictReader(f)
              for row in reader:
                  ip = row['ExitIP']
                  if ip in ip_to_country:
                      geo_data = ip_to_country[ip]
                      row['CountryCode'] = geo_data['country_code']
                      row['CountryName'] = geo_data['country_name']
                      row['City'] = geo_data['city']
                      row['Source'] = 'Onionoo API'
                  enriched_rows.append(row)
          
          # Write enriched CSV
          with open('ExternalData/TorExitNodes.csv', 'w', newline='') as f:
              if enriched_rows:
                  writer = csv.DictWriter(f, fieldnames=enriched_rows[0].keys())
                  writer.writeheader()
                  writer.writerows(enriched_rows)
          
          enriched_count = sum(1 for row in enriched_rows if row['CountryCode'])
          print(f'Enriched {enriched_count} out of {len(enriched_rows)} IPs with country data')
          "
      name: Pull TOR Exit Nodes Data

on:
  workflow_dispatch:
  schedule:
    - cron: "0 0 * * *"

jobs:
  pull-external-data:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Create directory
        run: mkdir -p ExternalData
      
      - name: Fetch all TOR sources
        run: |
          echo "Fetching TOR exit nodes from multiple sources..."
          
          curl -s "https://check.torproject.org/torbulkexitlist" > tor_bulk.txt
          echo "Bulk list: $(wc -l < tor_bulk.txt) lines"
          
          curl -s "https://onionoo.torproject.org/details?flag=Exit" > tor_onionoo.json
          echo "Onionoo API: $(wc -c < tor_onionoo.json) bytes"
          
          curl -s "https://torstatus.rueckgr.at/query_export.php/Tor_ip_list_EXIT.csv" > tor_rueckgr.csv
          echo "Rueckgr CSV: $(wc -l < tor_rueckgr.csv) lines"
          
          curl -s "https://www.dan.me.uk/torlist/" > tor_dan.txt
          echo "Dan.me.uk: $(wc -l < tor_dan.txt) lines"
          
          curl -s "https://api.hackertarget.com/torexit/?q=list" > tor_hackertarget.txt
          echo "HackerTarget: $(wc -l < tor_hackertarget.txt) lines"
      
      - name: Process data
        run: |
          echo "Processing and combining data..."
          
          # Initialize
          touch all_ips.txt
          touch enriched_data.json
          
          # Create enriched data from Onionoo API first (has country info)
          if command -v jq >/dev/null && [ -s tor_onionoo.json ]; then
            echo "Extracting enriched data from Onionoo API..."
            jq -r '.relays[] | select(.exit_addresses != null) | {
              ips: (.exit_addresses // .or_addresses),
              country: .country,
              country_name: .country_name,
              city: .city_name,
              nickname: .nickname,
              flags: .flags
            }' tor_onionoo.json > relay_info.json
            
            # Extract IPs with country info to temp file
            jq -r '.relays[] | select(.exit_addresses != null) | 
              (.exit_addresses // .or_addresses)[] as $ip | 
              [$ip, .country, .country_name, .city_name] | @csv' tor_onionoo.json > enriched_ips.csv || true
          fi
          
          # Process bulk list (no country info)
          grep -E '^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+
      
      - name: Create JSON
        run: |
          python3 -c "
          import json
          import csv
          from datetime import datetime
          
          # Read enriched CSV data
          enriched_nodes = []
          try:
              with open('ExternalData/TorExitNodes.csv', 'r') as f:
                  reader = csv.DictReader(f)
                  for row in reader:
                      enriched_nodes.append({
                          'ip': row['ExitIP'],
                          'country_code': row['CountryCode'] or None,
                          'country_name': row['CountryName'] or None,
                          'city': row['City'] or None,
                          'source': row['Source']
                      })
          except:
              enriched_nodes = []
          
          # Create enriched JSON structure
          data = {
              'metadata': {
                  'source': 'Multiple TOR sources with country enrichment',
                  'sources': [
                      'https://check.torproject.org/torbulkexitlist',
                      'https://onionoo.torproject.org/details?flag=Exit',
                      'https://torstatus.rueckgr.at/query_export.php/Tor_ip_list_EXIT.csv',
                      'https://www.dan.me.uk/torlist/',
                      'https://api.hackertarget.com/torexit/?q=list'
                  ],
                  'updated': datetime.utcnow().isoformat() + 'Z',
                  'count': len(enriched_nodes),
                  'enrichment': {
                      'country_data_available': sum(1 for node in enriched_nodes if node['country_code']),
                      'enrichment_percentage': round(sum(1 for node in enriched_nodes if node['country_code']) / len(enriched_nodes) * 100, 1) if enriched_nodes else 0
                  }
              },
              'TorExitNodes': enriched_nodes
          }
          
          with open('ExternalData/TorExitNodes.json', 'w') as f:
              json.dump(data, f, indent=2)
          
          enriched_count = sum(1 for node in enriched_nodes if node['country_code'])
          print(f'Created JSON with {len(enriched_nodes)} IPs ({enriched_count} with country data)')
          "
          
          # Show country distribution
          echo "Country distribution:"
          if [ -s ExternalData/TorExitNodes.csv ]; then
            tail -n +2 ExternalData/TorExitNodes.csv | cut -d',' -f3 | grep -v '^
      
      - name: Cleanup
        run: rm -f tor_*.txt tor_*.json tor_*.csv all_ips.txt unique_ips.txt
      
      - name: Commit changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "Update TOR exit nodes"
          file_pattern: 'ExternalData/TorExitNodes.*'
          push_options: '--force-with-lease' tor_bulk.txt >> all_ips.txt || true
          
          # Process Onionoo for IPs
          if command -v jq >/dev/null; then
            jq -r '.relays[]?.exit_addresses[]? // .relays[]?.or_addresses[]?' tor_onionoo.json 2>/dev/null | grep -E '^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+' | sed 's/:[0-9]*$//' >> all_ips.txt || true
          fi
          
          # Process other sources (no country info)
          tail -n +2 tor_rueckgr.csv | cut -d',' -f1 | grep -E '^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+' >> all_ips.txt || true
          grep -E '^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+
      
      - name: Create JSON
        run: |
          python3 -c "
          import json
          from datetime import datetime
          
          with open('validated_ips.txt', 'r') as f:
              ips = [line.strip() for line in f if line.strip()]
          
          data = {
              'metadata': {
                  'source': 'Multiple TOR sources',
                  'updated': datetime.utcnow().isoformat() + 'Z',
                  'count': len(ips)
              },
              'TorExitNodes': ips
          }
          
          with open('ExternalData/TorExitNodes.json', 'w') as f:
              json.dump(data, f, indent=2)
          
          print(f'Created JSON with {len(ips)} IPs')
          "
      
      - name: Cleanup
        run: rm -f tor_*.txt tor_*.json tor_*.csv all_ips.txt validated_ips.txt
      
      - name: Commit changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "Update TOR exit nodes"
          file_pattern: 'ExternalData/TorExitNodes.*'
          push_options: '--force-with-lease' tor_dan.txt >> all_ips.txt || true
          grep -E '^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+
      
      - name: Create JSON
        run: |
          python3 -c "
          import json
          from datetime import datetime
          
          with open('validated_ips.txt', 'r') as f:
              ips = [line.strip() for line in f if line.strip()]
          
          data = {
              'metadata': {
                  'source': 'Multiple TOR sources',
                  'updated': datetime.utcnow().isoformat() + 'Z',
                  'count': len(ips)
              },
              'TorExitNodes': ips
          }
          
          with open('ExternalData/TorExitNodes.json', 'w') as f:
              json.dump(data, f, indent=2)
          
          print(f'Created JSON with {len(ips)} IPs')
          "
      
      - name: Cleanup
        run: rm -f tor_*.txt tor_*.json tor_*.csv all_ips.txt validated_ips.txt
      
      - name: Commit changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "Update TOR exit nodes"
          file_pattern: 'ExternalData/TorExitNodes.*'
          push_options: '--force-with-lease' tor_hackertarget.txt >> all_ips.txt || true
          
          # Get unique IPs
          sort all_ips.txt | uniq > unique_ips.txt
          
          total_ips=$(wc -l < unique_ips.txt)
          echo "Total unique IPs: $total_ips"
          
          # Create enriched CSV
          echo "ExitIP,CountryCode,CountryName,City,Source" > ExternalData/TorExitNodes.csv
          
          # First add IPs with country info from Onionoo
          if [ -s enriched_ips.csv ]; then
            while IFS=',' read -r ip country country_name city; do
              # Remove quotes from CSV parsing
              ip=$(echo "$ip" | tr -d '"')
              country=$(echo "$country" | tr -d '"')
              country_name=$(echo "$country_name" | tr -d '"')
              city=$(echo "$city" | tr -d '"')
              echo "$ip,$country,$country_name,$city,Onionoo API" >> ExternalData/TorExitNodes.csv
            done < enriched_ips.csv
          fi
          
          # Add remaining IPs without country info
          while read ip; do
            if ! grep -q "^$ip," ExternalData/TorExitNodes.csv 2>/dev/null; then
              echo "$ip,,,Other Sources" >> ExternalData/TorExitNodes.csv
            fi
          done < unique_ips.txt
          
          enriched_count=$(grep -c "Onionoo API" ExternalData/TorExitNodes.csv || echo 0)
          echo "IPs with country info: $enriched_count"
      
      - name: Create JSON
        run: |
          python3 -c "
          import json
          from datetime import datetime
          
          with open('validated_ips.txt', 'r') as f:
              ips = [line.strip() for line in f if line.strip()]
          
          data = {
              'metadata': {
                  'source': 'Multiple TOR sources',
                  'updated': datetime.utcnow().isoformat() + 'Z',
                  'count': len(ips)
              },
              'TorExitNodes': ips
          }
          
          with open('ExternalData/TorExitNodes.json', 'w') as f:
              json.dump(data, f, indent=2)
          
          print(f'Created JSON with {len(ips)} IPs')
          "
      
      - name: Cleanup
        run: rm -f tor_*.txt tor_*.json tor_*.csv all_ips.txt validated_ips.txt
      
      - name: Commit changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "Update TOR exit nodes"
          file_pattern: 'ExternalData/TorExitNodes.*'
          push_options: '--force-with-lease' | sort | uniq -c | sort -nr | head -10
          fi
      
      - name: Cleanup
        run: rm -f tor_*.txt tor_*.json tor_*.csv all_ips.txt validated_ips.txt
      
      - name: Commit changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "Update TOR exit nodes"
          file_pattern: 'ExternalData/TorExitNodes.*'
          push_options: '--force-with-lease' tor_bulk.txt >> all_ips.txt || true
          
          # Process Onionoo for IPs
          if command -v jq >/dev/null; then
            jq -r '.relays[]?.exit_addresses[]? // .relays[]?.or_addresses[]?' tor_onionoo.json 2>/dev/null | grep -E '^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+' | sed 's/:[0-9]*$//' >> all_ips.txt || true
          fi
          
          # Process other sources (no country info)
          tail -n +2 tor_rueckgr.csv | cut -d',' -f1 | grep -E '^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+' >> all_ips.txt || true
          grep -E '^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+
      
      - name: Create JSON
        run: |
          python3 -c "
          import json
          from datetime import datetime
          
          with open('validated_ips.txt', 'r') as f:
              ips = [line.strip() for line in f if line.strip()]
          
          data = {
              'metadata': {
                  'source': 'Multiple TOR sources',
                  'updated': datetime.utcnow().isoformat() + 'Z',
                  'count': len(ips)
              },
              'TorExitNodes': ips
          }
          
          with open('ExternalData/TorExitNodes.json', 'w') as f:
              json.dump(data, f, indent=2)
          
          print(f'Created JSON with {len(ips)} IPs')
          "
      
      - name: Cleanup
        run: rm -f tor_*.txt tor_*.json tor_*.csv all_ips.txt validated_ips.txt
      
      - name: Commit changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "Update TOR exit nodes"
          file_pattern: 'ExternalData/TorExitNodes.*'
          push_options: '--force-with-lease' tor_dan.txt >> all_ips.txt || true
          grep -E '^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+
      
      - name: Create JSON
        run: |
          python3 -c "
          import json
          from datetime import datetime
          
          with open('validated_ips.txt', 'r') as f:
              ips = [line.strip() for line in f if line.strip()]
          
          data = {
              'metadata': {
                  'source': 'Multiple TOR sources',
                  'updated': datetime.utcnow().isoformat() + 'Z',
                  'count': len(ips)
              },
              'TorExitNodes': ips
          }
          
          with open('ExternalData/TorExitNodes.json', 'w') as f:
              json.dump(data, f, indent=2)
          
          print(f'Created JSON with {len(ips)} IPs')
          "
      
      - name: Cleanup
        run: rm -f tor_*.txt tor_*.json tor_*.csv all_ips.txt validated_ips.txt
      
      - name: Commit changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "Update TOR exit nodes"
          file_pattern: 'ExternalData/TorExitNodes.*'
          push_options: '--force-with-lease' tor_hackertarget.txt >> all_ips.txt || true
          
          # Get unique IPs
          sort all_ips.txt | uniq > unique_ips.txt
          
          total_ips=$(wc -l < unique_ips.txt)
          echo "Total unique IPs: $total_ips"
          
          # Create enriched CSV
          echo "ExitIP,CountryCode,CountryName,City,Source" > ExternalData/TorExitNodes.csv
          
          # First add IPs with country info from Onionoo
          if [ -s enriched_ips.csv ]; then
            while IFS=',' read -r ip country country_name city; do
              # Remove quotes from CSV parsing
              ip=$(echo "$ip" | tr -d '"')
              country=$(echo "$country" | tr -d '"')
              country_name=$(echo "$country_name" | tr -d '"')
              city=$(echo "$city" | tr -d '"')
              echo "$ip,$country,$country_name,$city,Onionoo API" >> ExternalData/TorExitNodes.csv
            done < enriched_ips.csv
          fi
          
          # Add remaining IPs without country info
          while read ip; do
            if ! grep -q "^$ip," ExternalData/TorExitNodes.csv 2>/dev/null; then
              echo "$ip,,,Other Sources" >> ExternalData/TorExitNodes.csv
            fi
          done < unique_ips.txt
          
          enriched_count=$(grep -c "Onionoo API" ExternalData/TorExitNodes.csv || echo 0)
          echo "IPs with country info: $enriched_count"
      
      - name: Create JSON
        run: |
          python3 -c "
          import json
          from datetime import datetime
          
          with open('validated_ips.txt', 'r') as f:
              ips = [line.strip() for line in f if line.strip()]
          
          data = {
              'metadata': {
                  'source': 'Multiple TOR sources',
                  'updated': datetime.utcnow().isoformat() + 'Z',
                  'count': len(ips)
              },
              'TorExitNodes': ips
          }
          
          with open('ExternalData/TorExitNodes.json', 'w') as f:
              json.dump(data, f, indent=2)
          
          print(f'Created JSON with {len(ips)} IPs')
          "
      
      - name: Cleanup
        run: rm -f tor_*.txt tor_*.json tor_*.csv all_ips.txt validated_ips.txt
      
      - name: Commit changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "Update TOR exit nodes"
          file_pattern: 'ExternalData/TorExitNodes.*'
          push_options: '--force-with-lease'
